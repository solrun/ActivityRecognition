{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5979df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ad49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_file(df):\n",
    "    df = df[0].str.split('\\t', n=4, expand=True)\n",
    "\n",
    "    df.columns = [\"time\", \"sensor\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "    GYR_data = df.loc[df['sensor'] == 'GYR']\n",
    "    ACC_data = df.loc[df['sensor'] == 'ACC']\n",
    "\n",
    "    GYR_data.index = GYR_data['time'].apply(pd.to_numeric)\n",
    "    ACC_data.index = ACC_data['time'].apply(pd.to_numeric)\n",
    "    GYR_data = GYR_data.drop('sensor', axis=1)\n",
    "    ACC_data = ACC_data.drop('sensor', axis=1)\n",
    "    GYR_data.columns = ['time_gyr', \"gyr_x\", \"gyr_y\", \"gyr_z\"]\n",
    "    ACC_data.columns = ['time_acc', \"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "    \n",
    "    GYR_data = GYR_data.apply(pd.to_numeric)\n",
    "    ACC_data = ACC_data.apply(pd.to_numeric)\n",
    "    \n",
    "    min_idx = np.argmin([ACC_data.shape[0], GYR_data.shape[0]]) \n",
    "    max_idx = np.argmax([ACC_data.shape[0], GYR_data.shape[0]])  \n",
    "\n",
    "    data_acc_gyr = [ACC_data, GYR_data] \n",
    "    data_acc_gyr[max_idx] = data_acc_gyr[max_idx].reindex(data_acc_gyr[min_idx].index, method='nearest', tolerance=0.02)\n",
    "    new_set = pd.concat(data_acc_gyr, axis=1)\n",
    "    new_set2 = new_set.dropna().reset_index(drop=True)\n",
    "    return new_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9303c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "data_running_oscar = structure_file(pd.read_csv('running/running_oscar.txt', header=None))\n",
    "data_walking_walking = structure_file(pd.read_csv('walking/walking_oscar.txt', header=None))\n",
    "data_standing_oscar = structure_file(pd.read_csv('standing_still/standing_still_oscar.txt', header=None))\n",
    "\n",
    "data_running_oscar = structure_file(pd.read_csv('running/running_oscar.txt', header=None))\n",
    "data_walking_walking = structure_file(pd.read_csv('walking/walking_oscar.txt', header=None))\n",
    "data_standing_oscar = structure_file(pd.read_csv('standing_still/standing_still_oscar.txt', header=None))\n",
    "\n",
    "all_data = {'running':[],\n",
    "           'walking':[],\n",
    "           'standing_still':[]}\n",
    "\n",
    "\n",
    "data_types = [\"standing_still\", \"walking\", \"running\"]\n",
    "current_path = os.path.abspath('.')\n",
    "for data_type in data_types:\n",
    "    data_path = os.path.join(current_path, data_type)\n",
    "    for file in os.listdir(data_path):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        data = pd.read_csv(file_path, header=None)\n",
    "        pandas_data = structure_file(data)\n",
    "        all_data[data_type].append(pandas_data)\n",
    "        # pprint(pandas_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eba7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create sequence of data\n",
    "num_channels = 6\n",
    "time_series_len = 200\n",
    "\n",
    "num_samples = 0\n",
    "for key in all_data:\n",
    "    for data_sample in all_data[key]:\n",
    "        nr_sample = 0\n",
    "        while nr_sample < data_sample.shape[0]//time_series_len -1:\n",
    "            nr_sample += 1\n",
    "            num_samples += 1            \n",
    "\n",
    "data_np = np.zeros((num_samples, num_channels, time_series_len))\n",
    "label_np = np.zeros(num_samples)\n",
    "\n",
    "key_to_label = {'running': 0,\n",
    "                'walking': 1,\n",
    "                'standing_still': 2}\n",
    "\n",
    "channels = ['acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z']\n",
    "\n",
    "nr_sample = 0\n",
    "for key in all_data:\n",
    "    nr_sub_sample = 0\n",
    "    for data_sample in all_data[key]:\n",
    "        start_v = 0\n",
    "        while nr_sub_sample < data_sample.shape[0]//time_series_len - 1:\n",
    "            label_np[nr_sample] = key_to_label[key] \n",
    "            for i in range(num_channels):\n",
    "                data_key = channels[i]\n",
    "                data_np[nr_sample, i, :] = data_sample[data_key].iloc[start_v: start_v+time_series_len]\n",
    "            \n",
    "            start_v += time_series_len\n",
    "            nr_sub_sample += 1\n",
    "            nr_sample += 1\n",
    "            \n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(data_np, label_np, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653c1b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 2., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       2., 1., 2., 2., 1., 1., 0., 1., 0., 0., 2., 1., 0., 0., 0., 0., 0.,\n",
       "       2., 1., 0., 0., 0., 0., 0., 0., 2., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 2., 2., 2., 2., 2., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 2.,\n",
       "       2., 0., 1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 2., 2., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 2., 2.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 2., 0., 0., 0., 0., 2., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 1., 1., 2., 2.,\n",
       "       1., 0., 0., 0., 1., 0., 2., 0., 1., 0., 2., 0., 0., 1., 0., 2., 0.,\n",
       "       0., 0., 1., 2., 0., 0., 1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 2., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 2., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 2., 0., 0., 2., 0., 2., 2., 0., 0., 2., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 2., 0.,\n",
       "       1., 1., 1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 2., 2., 0., 2., 0.,\n",
       "       2., 2., 0., 0., 1., 0., 2., 1., 0., 2., 0., 0., 0., 1., 2., 0., 2.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 2.,\n",
       "       1., 1., 0., 0., 2., 1., 1., 0., 0., 0., 0., 2., 0., 1., 2., 0., 0.,\n",
       "       2., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 2., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 2., 0., 0., 2., 0., 0., 0., 0., 0., 1., 2., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 2., 2., 0., 2., 0., 2., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
